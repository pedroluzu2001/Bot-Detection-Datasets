{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d299d4ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtextblob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Configuración para mostrar todas las columnas\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración para mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Librerías importadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197625ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar los datasets originales\n",
    "# Asumimos que los archivos tienen extensión .csv\n",
    "df_luisa = pd.read_csv('data//Comentarios_Extraidos - Comments_Luisa.csv')\n",
    "df_noboa = pd.read_csv('data//Comentarios_Extraidos - Comments_Noboa.csv')\n",
    "\n",
    "# Agregar una columna temporal para identificar la fuente (opcional, pero útil para depurar)\n",
    "df_luisa['candidate_target'] = 'Luisa Gonzalez'\n",
    "df_noboa['candidate_target'] = 'Daniel Noboa'\n",
    "\n",
    "# 2. Unir los dataframes (Concatenación)\n",
    "df = pd.concat([df_luisa, df_noboa], ignore_index=True)\n",
    "\n",
    "# 3. Eliminar duplicados exactos (basado en tweetId)\n",
    "initial_len = len(df)\n",
    "df = df.drop_duplicates(subset=['tweetId'], keep='first')\n",
    "print(f\"Filas iniciales: {initial_len}, Filas tras eliminar duplicados: {len(df)}\")\n",
    "\n",
    "# Reiniciar el índice\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_twitter_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    # Limpiamos espacios extra\n",
    "    date_str = str(date_str).strip()\n",
    "    # Formato: \"February 8, 2025 at 01:08 PM\"\n",
    "    # %B = Mes completo, %d = día, %Y = Año, %I = Hora 12h, %M = Minutos, %p = AM/PM\n",
    "    try:\n",
    "        return datetime.strptime(date_str, \"%B %d, %Y at %I:%M %p\")\n",
    "    except ValueError:\n",
    "        # En caso de que haya algún formato extraño, retornamos NaT\n",
    "        return pd.NaT\n",
    "\n",
    "# Aplicamos la conversión a 'createdAt' y 'authorJoinDate'\n",
    "print(\"Procesando fechas... (esto puede tardar unos segundos)\")\n",
    "df['createdAt_dt'] = df['createdAt'].apply(parse_twitter_date)\n",
    "df['authorJoinDate_dt'] = df['authorJoinDate'].apply(parse_twitter_date)\n",
    "\n",
    "# Creamos la columna 'Date' simple (solo fecha, sin hora) solicitada\n",
    "df['Date'] = df['createdAt_dt'].dt.date\n",
    "\n",
    "# Verificar que no haya NaT (Not a Time)\n",
    "print(f\"Fechas fallidas: {df['createdAt_dt'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e14116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Limpieza básica para conteo de palabras\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Quitar URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Quitar caracteres especiales pero dejar puntuación básica\n",
    "    return text.strip()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"Calcula polaridad con TextBlob (-1 a 1)\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# --- 1. Variables Temporales ---\n",
    "# Edad de la cuenta en días al momento del tweet\n",
    "df['account_age_days'] = (df['createdAt_dt'] - df['authorJoinDate_dt']).dt.days\n",
    "# Si sale negativo por error de zona horaria o creación el mismo día, poner 0\n",
    "df['account_age_days'] = df['account_age_days'].apply(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "# --- 2. Variables de Texto y Estructura ---\n",
    "# Conteos básicos\n",
    "df['content_length'] = df['content'].fillna(\"\").apply(len)\n",
    "df['mentions_count'] = df['content'].fillna(\"\").apply(lambda x: x.count('@'))\n",
    "df['hashtags_count'] = df['content'].fillna(\"\").apply(lambda x: x.count('#'))\n",
    "\n",
    "# Ratios y Estadísticas de Texto\n",
    "def text_features(row):\n",
    "    text = str(row['content'])\n",
    "    if not text:\n",
    "        return pd.Series([0.0, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    # Uppercase Ratio (Gritos)\n",
    "    uppercase_chars = sum(1 for c in text if c.isupper())\n",
    "    uppercase_ratio = uppercase_chars / len(text) if len(text) > 0 else 0\n",
    "    \n",
    "    # Palabras\n",
    "    words = clean_text(text).split()\n",
    "    num_words = len(words)\n",
    "    \n",
    "    if num_words == 0:\n",
    "        return pd.Series([uppercase_ratio, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    # Unique Word Ratio (Riqueza léxica)\n",
    "    unique_words = len(set(words))\n",
    "    unique_word_ratio = unique_words / num_words\n",
    "    \n",
    "    # Avg Word Length\n",
    "    avg_word_length = sum(len(w) for w in words) / num_words\n",
    "    \n",
    "    # Mention to word ratio\n",
    "    mention_ratio = row['mentions_count'] / num_words\n",
    "    \n",
    "    return pd.Series([uppercase_ratio, unique_word_ratio, avg_word_length, mention_ratio])\n",
    "\n",
    "# Aplicar la función de ratios\n",
    "print(\"Calculando estadísticas de texto...\")\n",
    "df[['uppercase_ratio', 'unique_word_ratio', 'avg_word_length', 'mention_to_word_ratio']] = df.apply(text_features, axis=1)\n",
    "\n",
    "# --- 3. Variables de Perfil ---\n",
    "# has_profile_picture: Asumimos que si la URL contiene \"default\", es falsa.\n",
    "# Ajusta esto si tus datos tienen otra lógica (ej. si la URL está vacía)\n",
    "df['has_profile_picture'] = df['authorProfilePic'].fillna(\"default\").apply(\n",
    "    lambda x: False if \"default\" in str(x).lower() else True\n",
    ")\n",
    "\n",
    "# --- 4. Sentimiento (Polaridad) ---\n",
    "# Nota: Esto es preliminar antes de los Intents avanzados\n",
    "print(\"Calculando sentimiento (TextBlob)...\")\n",
    "df['sentiment_polarity'] = df['content'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2957c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario de ID -> Fecha de Creación para búsqueda rápida\n",
    "tweet_time_map = pd.Series(df.createdAt_dt.values, index=df.tweetId).to_dict()\n",
    "\n",
    "def calculate_response_time(row):\n",
    "    \"\"\"\n",
    "    Calcula minutos entre el tweet y el tweet al que responde.\n",
    "    Si no encuentra el padre en el dataset, retorna NaN (o -1).\n",
    "    \"\"\"\n",
    "    if pd.isna(row['inReplyToId']):\n",
    "        return -1 # No es respuesta o no hay ID\n",
    "    \n",
    "    parent_id = row['inReplyToId']\n",
    "    \n",
    "    # Buscamos si tenemos la fecha del padre en nuestro dataset descargado\n",
    "    if parent_id in tweet_time_map:\n",
    "        parent_time = tweet_time_map[parent_id]\n",
    "        current_time = row['createdAt_dt']\n",
    "        \n",
    "        # Diferencia en minutos\n",
    "        diff = (current_time - parent_time).total_seconds() / 60.0\n",
    "        return diff if diff >= 0 else 0\n",
    "    else:\n",
    "        # El tweet padre no está en nuestro dataset (ej. tweet del candidato muy antiguo)\n",
    "        # Aquí decidimos qué hacer: Dejar NaN o poner 0.\n",
    "        # Para la GNN a veces se imputa con la media, aquí dejaremos NaN para tratarlo luego.\n",
    "        return np.nan\n",
    "\n",
    "print(\"Calculando tiempos de respuesta...\")\n",
    "df['time_response'] = df.apply(calculate_response_time, axis=1)\n",
    "\n",
    "# Imputar valores nulos en time_response si es necesario (ej. con la media)\n",
    "# Ojo: Si es NaN significa que no tenemos el padre.\n",
    "# Para evitar errores en CSV, llenaremos con -1 o 0 según prefieras.\n",
    "df['time_response'] = df['time_response'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe44193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas deseadas en orden\n",
    "desired_columns = [\n",
    "    'tweetId', 'tweetUrl', 'content', 'isReply', 'replyTo', 'createdAt',\n",
    "    'authorId', 'authorName', 'authorUsername', 'authorVerified', \n",
    "    'authorFollowers', 'authorProfilePic', 'authorJoinDate', 'source', \n",
    "    'hashtags', 'mentions', 'conversationId', 'inReplyToId',\n",
    "    # Features generadas\n",
    "    'Date', 'time_response', 'account_age_days', 'mentions_count', \n",
    "    'hashtags_count', 'content_length', 'has_profile_picture', \n",
    "    'sentiment_polarity', 'uppercase_ratio', 'unique_word_ratio', \n",
    "    'avg_word_length', 'mention_to_word_ratio'\n",
    "]\n",
    "\n",
    "# Filtramos (asegurando que existan todas)\n",
    "df_final = df[desired_columns].copy()\n",
    "\n",
    "# Verificación final\n",
    "print(f\"Shape final: {df_final.shape}\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c41e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'tweets.csv'\n",
    "df_final.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✅ Archivo generado exitosamente: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
